{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pradyumna4998/Intro-to-ML/blob/main/HW7_Q1_IntroToML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Introduction to Machine Learning\n",
        "                              Homework 7\n",
        "\n",
        "Name: V.pradyumna\n",
        "\n",
        "Student ID : 801345963\n"
      ],
      "metadata": {
        "id": "CeeRFu4oZI28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJvAqDbFZOmm",
        "outputId": "16366fa7-a035-4fd1-cc02-51e908fe1b0b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipython-autotime in /usr/local/lib/python3.10/dist-packages (0.3.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipython-autotime) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (75.1.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.13)\n",
            "The autotime extension is already loaded. To reload it, use:\n",
            "  %reload_ext autotime\n",
            "time: 2.21 s (started: 2024-12-04 17:01:54 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "torch.set_printoptions(edgeitems=2)\n",
        "torch.manual_seed(123)\n",
        "np.random.seed(123)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSbrwgU8ZVVk",
        "outputId": "bc122e20-1a48-4e5d-94dd-6c17d8898663"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.06 ms (started: 2024-12-04 17:01:56 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H24cHjVLZcMs",
        "outputId": "044c9f67-c8b3-41fb-d9cb-b8401b3fd174"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.06 ms (started: 2024-12-04 17:01:56 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "training_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "# Calculating mean and standard(std)\n",
        "images = torch.stack([img_t for img_t, _ in training_dataset], dim=3)\n",
        "mean = images.view(3, -1).mean(dim=1)\n",
        "std = images.view(3, -1).std(dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gorg1tI8ZdSZ",
        "outputId": "04cf9814-446b-459f-8085-6bf9dce63f3f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "time: 24.2 s (started: 2024-12-04 17:01:56 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lgyAnoiZmG5",
        "outputId": "d2103974-64b9-4768-f5ec-687b12b0a60f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4914, 0.4822, 0.4465])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.47 ms (started: 2024-12-04 17:02:20 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "std"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MJEwzm4ZoSp",
        "outputId": "e83ced29-a33e-402d-b0b8-2b5f8b1c7bd5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2470, 0.2435, 0.2616])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.62 ms (started: 2024-12-04 17:02:20 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10 = datasets.CIFAR10(\n",
        "    './data', train=True, download=False,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYUOx2xdZpz9",
        "outputId": "465602ac-47ad-4359-8e4e-9e3ec838d02f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 556 ms (started: 2024-12-04 17:02:20 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10_testing = datasets.CIFAR10(\n",
        "     './data', train=False, download=False,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUNkicjDZsDy",
        "outputId": "465fef2f-d660-44fb-e748-72b91db9ad12"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 387 ms (started: 2024-12-04 17:02:21 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "image1, label = cifar10[0]\n",
        "print(image1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOLzHKwxZuPM",
        "outputId": "3fc77100-5240-44ea-fba3-a239de7d4d08"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 32, 32])\n",
            "time: 2 ms (started: 2024-12-04 17:02:21 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_loader = DataLoader(cifar10, batch_size=32, shuffle=True, num_workers=2)\n",
        "testing_loader = DataLoader(cifar10_testing, batch_size=32, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGM8u-FcZxbm",
        "outputId": "58a806d3-3f0c-4255-fef7-f80492dd775d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 609 µs (started: 2024-12-04 17:02:21 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rQjudY3Zz5o",
        "outputId": "28862682-a6ab-44f0-fe9c-c8e5bdee4223"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.22 ms (started: 2024-12-04 17:02:21 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "        self.act1 = nn.Tanh()\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
        "        self.act2 = nn.Tanh()\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
        "        self.act3 = nn.Tanh()\n",
        "        self.fc2 = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.pool1(self.act1(self.conv1(x)))\n",
        "        out = self.pool2(self.act2(self.conv2(out)))\n",
        "        out = out.view(-1, 8 * 8 * 8) # <1>\n",
        "        out = self.act3(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaXiwYRHZ3kx",
        "outputId": "34ef04c5-dd15-459a-ae4f-861517c71635"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 977 µs (started: 2024-12-04 17:02:21 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Net().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZ48zWA2Z6Zs",
        "outputId": "a9c650c5-1c40-430d-e9f4-10b51ac18493"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.28 ms (started: 2024-12-04 17:02:21 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numel_list = [p.numel() for p in model.parameters()]\n",
        "sum(numel_list), numel_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcfs2xX1Z9XJ",
        "outputId": "177e3620-0715-4014-b54e-8a200d79bb1d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18354, [432, 16, 1152, 8, 16384, 32, 320, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 5 ms (started: 2024-12-04 17:02:21 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "def training_loop(epochs, optimizer, model, loss_function, training_loader):\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        training_loss = 0.0\n",
        "        for images, labels in training_loader:\n",
        "            images = images.to(device=device)  # <1>\n",
        "            labels = labels.to(device=device)\n",
        "            outputs = model(images)\n",
        "            loss = loss_function(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            training_loss += loss.item()\n",
        "\n",
        "        if epoch == 1 or epoch % 2 == 0:\n",
        "            print('{} Epoch {}, Training loss {}'.format(\n",
        "                datetime.datetime.now(), epoch, training_loss/ len(training_loader)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64CWsdM0aAYI",
        "outputId": "0813af76-3a8a-4c5e-80a1-4ee15265354a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.41 ms (started: 2024-12-04 17:02:21 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
        "                                           shuffle=True)\n",
        "\n",
        "model = Net().to(device=device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "training_loop(\n",
        "    epochs = 200,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_function = loss_function,\n",
        "    training_loader = training_loader,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QADGh2ylaDH4",
        "outputId": "234003bc-50a9-49ca-b885-84423050ed43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-04 17:02:47.482296 Epoch 1, Training loss 2.06806315012905\n",
            "2024-12-04 17:03:05.900147 Epoch 2, Training loss 1.7975618258461623\n",
            "2024-12-04 17:03:32.787536 Epoch 4, Training loss 1.5253500965855005\n",
            "2024-12-04 17:04:00.177508 Epoch 6, Training loss 1.3815415445953378\n",
            "2024-12-04 17:04:27.038645 Epoch 8, Training loss 1.2716946279453805\n",
            "2024-12-04 17:04:54.215582 Epoch 10, Training loss 1.193928534493727\n",
            "2024-12-04 17:05:21.603234 Epoch 12, Training loss 1.1361413646841902\n",
            "2024-12-04 17:05:48.577601 Epoch 14, Training loss 1.0900413743827655\n",
            "2024-12-04 17:06:15.598092 Epoch 16, Training loss 1.0553654136560153\n",
            "2024-12-04 17:06:43.717572 Epoch 18, Training loss 1.0226405362034088\n",
            "2024-12-04 17:07:10.506114 Epoch 20, Training loss 0.995345059182028\n",
            "2024-12-04 17:07:37.324647 Epoch 22, Training loss 0.9691588150723206\n",
            "2024-12-04 17:08:04.255413 Epoch 24, Training loss 0.9483433722535057\n",
            "2024-12-04 17:08:30.835266 Epoch 26, Training loss 0.9291621108951471\n",
            "2024-12-04 17:08:57.562518 Epoch 28, Training loss 0.9137786405013345\n",
            "2024-12-04 17:09:24.091386 Epoch 30, Training loss 0.9006118940575348\n",
            "2024-12-04 17:09:50.683110 Epoch 32, Training loss 0.8850813591876603\n",
            "2024-12-04 17:10:18.047437 Epoch 34, Training loss 0.8753040537352452\n",
            "2024-12-04 17:10:44.556315 Epoch 36, Training loss 0.8643471064317562\n",
            "2024-12-04 17:11:11.247061 Epoch 38, Training loss 0.8551223825310807\n",
            "2024-12-04 17:11:37.935465 Epoch 40, Training loss 0.8447187847798437\n",
            "2024-12-04 17:12:04.616842 Epoch 42, Training loss 0.8369350558351678\n",
            "2024-12-04 17:12:31.452586 Epoch 44, Training loss 0.8276716309130344\n",
            "2024-12-04 17:12:58.662922 Epoch 46, Training loss 0.820137663532401\n",
            "2024-12-04 17:13:25.991485 Epoch 48, Training loss 0.812643553594799\n",
            "2024-12-04 17:13:52.690236 Epoch 50, Training loss 0.8062917255913206\n",
            "2024-12-04 17:14:19.408549 Epoch 52, Training loss 0.7997724794975632\n",
            "2024-12-04 17:14:46.172236 Epoch 54, Training loss 0.7927438135799545\n",
            "2024-12-04 17:15:13.015073 Epoch 56, Training loss 0.787163243307482\n",
            "2024-12-04 17:15:39.800455 Epoch 58, Training loss 0.7815692832936412\n",
            "2024-12-04 17:16:06.827193 Epoch 60, Training loss 0.774794154650415\n",
            "2024-12-04 17:16:33.882079 Epoch 62, Training loss 0.7701533032042901\n",
            "2024-12-04 17:17:01.109393 Epoch 64, Training loss 0.7644967361713004\n",
            "2024-12-04 17:17:27.776338 Epoch 66, Training loss 0.7591260039364286\n",
            "2024-12-04 17:17:54.511373 Epoch 68, Training loss 0.7520415329795969\n",
            "2024-12-04 17:18:21.141121 Epoch 70, Training loss 0.7476816096574145\n",
            "2024-12-04 17:18:47.634181 Epoch 72, Training loss 0.7428998073653492\n",
            "2024-12-04 17:19:14.270388 Epoch 74, Training loss 0.7393601220815688\n",
            "2024-12-04 17:19:40.835669 Epoch 76, Training loss 0.735120268047923\n",
            "2024-12-04 17:20:07.989085 Epoch 78, Training loss 0.7305582712221024\n",
            "2024-12-04 17:20:34.774699 Epoch 80, Training loss 0.7252546855250893\n",
            "2024-12-04 17:21:01.257125 Epoch 82, Training loss 0.7225579809959587\n",
            "2024-12-04 17:21:27.782095 Epoch 84, Training loss 0.7182092239408542\n",
            "2024-12-04 17:21:54.169061 Epoch 86, Training loss 0.7139357219800315\n",
            "2024-12-04 17:22:20.774351 Epoch 88, Training loss 0.7112183803716279\n",
            "2024-12-04 17:22:47.156349 Epoch 90, Training loss 0.7062241655710103\n",
            "2024-12-04 17:23:13.920533 Epoch 92, Training loss 0.7029063507266666\n",
            "2024-12-04 17:23:40.650097 Epoch 94, Training loss 0.6998881640489144\n",
            "2024-12-04 17:24:07.692251 Epoch 96, Training loss 0.6953595148404236\n",
            "2024-12-04 17:24:34.001384 Epoch 98, Training loss 0.6934252913345766\n",
            "2024-12-04 17:25:00.436101 Epoch 100, Training loss 0.6895417207494721\n",
            "2024-12-04 17:25:26.893377 Epoch 102, Training loss 0.6857547031339172\n",
            "2024-12-04 17:25:53.136191 Epoch 104, Training loss 0.6826868702459823\n",
            "2024-12-04 17:26:19.479463 Epoch 106, Training loss 0.6805926073542641\n",
            "2024-12-04 17:26:45.601284 Epoch 108, Training loss 0.675856579714419\n",
            "2024-12-04 17:27:11.758565 Epoch 110, Training loss 0.6735628294517927\n",
            "2024-12-04 17:27:38.554178 Epoch 112, Training loss 0.6725484722334406\n",
            "2024-12-04 17:28:04.927306 Epoch 114, Training loss 0.6688350886106491\n",
            "2024-12-04 17:28:31.282193 Epoch 116, Training loss 0.665837310769064\n",
            "2024-12-04 17:28:57.751072 Epoch 118, Training loss 0.6636472622604321\n",
            "2024-12-04 17:29:24.057772 Epoch 120, Training loss 0.6604829310151317\n",
            "2024-12-04 17:29:50.216275 Epoch 122, Training loss 0.657167884623608\n",
            "2024-12-04 17:30:16.397323 Epoch 124, Training loss 0.6557733738590079\n",
            "2024-12-04 17:30:42.605484 Epoch 126, Training loss 0.6550100917553963\n",
            "2024-12-04 17:31:09.256193 Epoch 128, Training loss 0.6487581938352731\n",
            "2024-12-04 17:31:35.923922 Epoch 130, Training loss 0.6469651148142412\n",
            "2024-12-04 17:32:02.207098 Epoch 132, Training loss 0.6450807324532047\n",
            "2024-12-04 17:32:28.496741 Epoch 134, Training loss 0.6408549195436566\n",
            "2024-12-04 17:32:54.706146 Epoch 136, Training loss 0.6397878182361193\n",
            "2024-12-04 17:33:21.040312 Epoch 138, Training loss 0.6373104518255615\n",
            "2024-12-04 17:33:47.167009 Epoch 140, Training loss 0.6357890481076887\n",
            "2024-12-04 17:34:13.368115 Epoch 142, Training loss 0.6320414761905475\n",
            "2024-12-04 17:34:39.743570 Epoch 144, Training loss 0.6317485122729445\n",
            "2024-12-04 17:35:06.311530 Epoch 146, Training loss 0.6273866723413053\n",
            "2024-12-04 17:35:32.332197 Epoch 148, Training loss 0.6251540664592972\n",
            "2024-12-04 17:35:58.562727 Epoch 150, Training loss 0.6236016783110626\n",
            "2024-12-04 17:36:24.756184 Epoch 152, Training loss 0.6194785127554403\n",
            "2024-12-04 17:36:50.916754 Epoch 154, Training loss 0.6195138381112872\n",
            "2024-12-04 17:37:16.891536 Epoch 156, Training loss 0.6182429253521478\n",
            "2024-12-04 17:37:42.861435 Epoch 158, Training loss 0.615292333314181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader(cifar10_testing, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "all_acc_dict = collections.OrderedDict()\n",
        "\n",
        "def validate(model, train_loader, val_loader):\n",
        "    acc_dict = {}\n",
        "    predictions = []\n",
        "    exp_labels = []\n",
        "\n",
        "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in loader:\n",
        "                imgs = imgs.to(device=device)\n",
        "                labels = labels.to(device=device)\n",
        "                outputs = model(imgs)\n",
        "                _, predicted = torch.max(outputs, dim=1) # <1>\n",
        "                total += labels.shape[0]\n",
        "                correct += int((predicted == labels).sum())\n",
        "\n",
        "                predictions.extend(predicted.cpu().numpy())\n",
        "                exp_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
        "        acc_dict[name] = correct / total\n",
        "    return acc_dict, predictions, exp_labels"
      ],
      "metadata": {
        "id": "IiUypmhw1_R_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy, predictions, expected_labels = validate(model, train_loader, val_loader)"
      ],
      "metadata": {
        "id": "f1sS_RE82Lh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(predictions, expected_labels, target_names=class_names))"
      ],
      "metadata": {
        "id": "Jr0CA7Oh2VEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(predictions, expected_labels, average='macro')\n",
        "recall = recall_score(predictions, expected_labels, average='macro')\n",
        "cnf_matrix = confusion_matrix(predictions, expected_labels)"
      ],
      "metadata": {
        "id": "L9qXfZXj2Wci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cnf_matrix, annot=True, cmap=\"viridis\", fmt='g',\n",
        "            xticklabels = class_names, yticklabels = class_names)\n",
        "plt.title('Confusion Matrix for 2-Layer Convolutional Network')\n",
        "plt.ylabel('Actual Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=45)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N8tktkXg2Zu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem:1)b)"
      ],
      "metadata": {
        "id": "WdvlFSPO2noz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "        self.act1 = nn.Tanh()\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
        "        self.act2 = nn.Tanh()\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.conv3 = nn.Conv2d(8, 4, kernel_size=3, padding=1)\n",
        "        self.act3 = nn.Tanh()\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(4 * 4 * 4, 32)\n",
        "        self.act4 = nn.Tanh()\n",
        "        self.fc2 = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.pool1(self.act1(self.conv1(x)))\n",
        "        out = self.pool2(self.act2(self.conv2(out)))\n",
        "        out = self.pool3(self.act3(self.conv3(out)))\n",
        "        out = out.view(-1, 4 * 4 * 4)\n",
        "        out = self.act4(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "akT7hHHn2p9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Net2().to(device)"
      ],
      "metadata": {
        "id": "RDRRfkm32tPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numel_list = [p.numel() for p in model.parameters()]\n",
        "sum(numel_list), numel_list"
      ],
      "metadata": {
        "id": "phsCvRsb2vZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
        "                                           shuffle=True)\n",
        "\n",
        "model2 = Net2().to(device=device)\n",
        "optimizer2 = optim.SGD(model2.parameters(), lr=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "training_loop(\n",
        "    epochs = 200,\n",
        "    optimizer = optimizer2,\n",
        "    model = model2,\n",
        "    loss_function = loss_function,\n",
        "    training_loader = training_loader,\n",
        ")"
      ],
      "metadata": {
        "id": "vmNeyTFq2yFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loader = torch.utils.data.DataLoader(cifar10_testing, batch_size=64,\n",
        "                                         shuffle=False)"
      ],
      "metadata": {
        "id": "AS72R6OlHgvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy2, predictions2, expected_labels2 = validate(model2, training_loader, val_loader)"
      ],
      "metadata": {
        "id": "GLN-DRFdHoBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(classification_report(predictions2, expected_labels2, target_names=class_names))"
      ],
      "metadata": {
        "id": "VQrig0KVH3oX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision2 = precision_score(predictions2, expected_labels2, average='macro')\n",
        "recall2 = recall_score(predictions2, expected_labels2, average='macro')\n",
        "cnf_matrix2 = confusion_matrix(predictions2, expected_labels2)\n"
      ],
      "metadata": {
        "id": "LXlymUjnH7Hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cnf_matrix2, annot=True, cmap=\"viridis\", fmt='g',\n",
        "            xticklabels = class_names, yticklabels = class_names)\n",
        "plt.title('3 Layer Conv Confusion Matrix')\n",
        "plt.ylabel('Actual Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=45)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JfsFf-bRIAOj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}